{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDanj4oD6blvT0a2cJL+IO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Convolutional Neural Network"
      ],
      "metadata": {
        "id": "R1Q02G0ftT79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import libraries"
      ],
      "metadata": {
        "id": "ZY7vYDZktZBe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVJ2IQy__uGn",
        "outputId": "5443ae75-4800-405a-f1b2-493a8077f18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Pre Processing"
      ],
      "metadata": {
        "id": "M15stR5MuJO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing Training set"
      ],
      "metadata": {
        "id": "7WUBJTnfuMbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we are applying transformations to avoid overfitting (image augumentation)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    'dataset/training_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "vWlpF7XWuRS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing test data"
      ],
      "metadata": {
        "id": "9SWCmkzMwQOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set=test_datagen.flow_from_directory(\n",
        "    'dataset/test_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "EPJyIce2wUcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the CNN"
      ],
      "metadata": {
        "id": "KUlSNdYCw242"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "ykbHBEjMw9fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###s1: Convolution"
      ],
      "metadata": {
        "id": "LzUXE9q3w5ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "hb4DQhZLxGN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###s2: Pooling"
      ],
      "metadata": {
        "id": "1qlZMFDOynV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "lyI-raqjypYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Add Second Convulutional layer"
      ],
      "metadata": {
        "id": "9MdNDIIzzLnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "RwHUlOwWzO2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###s3:flattening"
      ],
      "metadata": {
        "id": "Wcbem3KIzbjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "KLTU0_abzePX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###s4: Full Connection"
      ],
      "metadata": {
        "id": "DhfUjoU03CAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "ncMkX2pY3FiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Output Layer"
      ],
      "metadata": {
        "id": "D_KLmHZE3Xfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "DfDItVmt3cnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train CNN"
      ],
      "metadata": {
        "id": "_YylcOSQ3nUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compiling CNN"
      ],
      "metadata": {
        "id": "nRD6ubQS3sQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "I_3bGNx931q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Traing CNN on Training set and eveluating onTest set"
      ],
      "metadata": {
        "id": "9WaspiIK3u75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x=training_set, validation_data=test_set, epochs=25)"
      ],
      "metadata": {
        "id": "t8RQePeT4Niw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Making a single prediction"
      ],
      "metadata": {
        "id": "fBpB3dp8414P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image=image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64, 64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image, axis=0)\n",
        "result=cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1 :\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "1XMTV-f846hG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}